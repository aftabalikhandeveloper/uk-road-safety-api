# Annual STATS19 Data Update Workflow
# Runs October 1st at 2:00 AM UTC (after September DfT release)

name: Annual STATS19 Update

on:
  schedule:
    - cron: '0 2 1 10 *'  # 2:00 AM UTC on October 1st
  workflow_dispatch:
    inputs:
      year:
        description: 'Specific year to download (leave empty for latest)'
        required: false
        default: ''
      full_refresh:
        description: 'Full refresh (clear existing data)'
        required: false
        default: 'false'
      download_all_years:
        description: 'Download all historical years'
        required: false
        default: 'false'

env:
  DATABASE_URL: ${{ secrets.DATABASE_URL }}

jobs:
  annual-stats19-update:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours for large downloads
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create data directory
        run: mkdir -p data/raw
      
      - name: Download and load STATS19 data
        run: |
          echo "Starting STATS19 annual update..."
          
          YEAR_ARG=""
          if [ -n "${{ github.event.inputs.year }}" ]; then
            YEAR_ARG="-y ${{ github.event.inputs.year }}"
          fi
          
          REFRESH_ARG=""
          if [ "${{ github.event.inputs.full_refresh }}" == "true" ]; then
            REFRESH_ARG="--full-refresh"
          fi
          
          if [ "${{ github.event.inputs.download_all_years }}" == "true" ]; then
            # Download all years from 2017 to current
            python -m etl.main stats19 --start-year 2017 $REFRESH_ARG
          else
            # Download latest year only
            python -m etl.main stats19 $YEAR_ARG $REFRESH_ARG
          fi
      
      - name: Update geographic boundaries (if needed)
        run: |
          echo "Checking for boundary updates..."
          # Only run on full refresh or if specifically requested
          if [ "${{ github.event.inputs.full_refresh }}" == "true" ]; then
            python -m etl.main geography --lsoa
          fi
      
      - name: Rebuild indexes
        run: |
          echo "Rebuilding database indexes..."
          # This would be a SQL script in production
          python -c "
          from etl.loaders.postgres import PostgresLoader
          loader = PostgresLoader()
          loader.execute_sql('REINDEX TABLE accidents')
          loader.execute_sql('ANALYZE accidents')
          print('Indexes rebuilt successfully')
          "
      
      - name: Refresh all statistics
        run: |
          echo "Refreshing all statistics..."
          python -m etl.main refresh-statistics
      
      - name: Generate annual report
        run: |
          echo "========================================"
          echo "STATS19 Annual Update Complete"
          echo "========================================"
          python -m etl.main test-connection
      
      - name: Notify on completion
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '✅ Annual STATS19 Update Complete',
              body: `The annual STATS19 data update has completed successfully.\n\nRun: ${context.runId}\n\nPlease verify the data.`,
              labels: ['etl-success', 'automated']
            })
      
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '❌ Annual STATS19 Update Failed',
              body: `The annual STATS19 update workflow failed.\n\nRun: ${context.runId}\n\nThis is critical - please investigate immediately.`,
              labels: ['etl-failure', 'automated', 'critical']
            })
